from shared.tools.global import ExtraGlobal
from shared.tools.thread import async
from shared.tools.meta import is_redundant_active
from functools import partial

from time import sleep
from random import random
from datetime import datetime
import re

from pymongo import MongoClient
from pymongo import *

#MongoDB Connection URI
uri = 'mongodb://ignitionUser:dsfasduwefnzy3848s%23@txmongowcs1.mouser.lan:27017/ignition?tls=true&tlsAllowInvalidCertificates=true&replicaSet=wcsRS1&tlsCAFile=C%3A%5CMongo%5Cmouser-lan-root-ca.crt&authMechanism=DEFAULT&authSource=ignition'

#MongoDB Database connection format
client = MongoClient(uri)
db=client.ignition
def cursorToList(cursor):
	listcursor = []
	for i in range(cursor.count()):
		listcursor.append(cursor.next())
		
	return listcursor
def log_event(mode, data):
	results = system.db.runPrepUpdate("""
		insert into Handshake_Log (
			mode
		,	barcode
		,	routecode
		,	destination
		,	seq
		,	get_time
		,	got_time
		,	sql_time
		) values (?,?,?,?,?,?,?,?)	
		""",[
			mode
		,	data['IGN_Barcode_Returned']
		,	data.get('IGN_RouteCode_Returned', data.get('RouteCode_Returned'))
		,	data['IGN_Destination_Returned']
		,	data['IGN_IndexID_Returned']		
		,	data.get('Get_Time')		
		,	data.get('Got_Time')
		,	data.get('Sql_Time')
		], 'SQLServer')
		
	
CACHE_LIFESPAN = 3.0 # seconds

CLEAR_WAIT_TIME  = 0.026
FAILSAFE_TIMEOUT = 6.0

ERROR_BARCODES = set(['', 'NOREAD'])

SEPATATOR_PATTERN = re.compile(u'[,]', re.UNICODE)
@async(name="Handshake2-GatherData")

def gather_data(source_path):
	"""
		Get the data that needs to be processed.
		
		This uses direct OPC reads on the spot, 
		  and writes the ACK as soon as it can.
	"""
	timestart = datetime.now().isoformat()
	Autostore_results = []
	parent_dest = '/'.join(source_path.split('/')[:-2] + ['Get_Data'])

	# read the needed values in
	sequence_id, barcode = [
		qv.value for qv in 
		system.tag.readBlocking([
			parent_dest + '/' + 'IGN_IndexID_Sent',
			parent_dest + '/' + 'IGN_Barcode_Sent'
			])]

	system.tag.writeAsync([parent_dest + '/' + 'IGN_GetData_ACK'], [True])
	
	barcodes = barcode.split(',')
	routing_barcodes = []
	#Sets Tote Query to empty array
	tote_query = []

	#Tote elements
	tote = 'RVT'
	
	if barcode == 'NOREAD':
		error_code = 'NOREAD'		
		# query the route directly
		results = system.db.runPrepQuery("""
		select r.*
		from route_table1 as r
		where r.route_code = ?
		""", [error_code],'SQLServer')
		
	elif SEPATATOR_PATTERN.findall(barcode):
	
		
		for token in SEPATATOR_PATTERN.split(barcodes):
			
			#If tote found add to array	
			if token.startswith("RVT") or token.startswith("TSBX"):
				tote_query.append(token)
					
			elif re.match('[0-9]{1}[0-9A-Z]{5}',token):
				if token not in routing_barcodes:
					routing_barcodes.append(check)
	elif barcode.startswith("RVT") or barcode.startswith("TSBX"):		
		tote_query.append(barcode)
	elif re.match('[0-9]{1}[0-9A-Z]{5}',barcode):
		routing_barcodes.append(barcode)
		
		
	
	if not routing_barcodes and not tote_query:
		zone = 'NOIBN'		
		# query the route directly
		
		
	elif len(tote_query) == 1:
		tote = tote_query[0]
		if tote.startswith('RVT'):
			zone = 'RVT'
		elif tote.startswith('TSBX'):
			zone = 'TSBX'
			
	
	else:
	
		filter={
			   "_id":{'$in':routing_barcodes}
			}
		project={
		    '_id': 1, 
		   'sort_size': 1, 
		   'zone': 1
		}
		
		IBNQuery = db.inbound_receipt_info.find(
				filter=filter,
				projection=project
				)
			
		
	
		IBNresults = cursorToList(IBNQuery)
		IBNQuery.close()
		IBNCount = len(IBNresults)					
		
		if IBNCount == 0:
			sortSize = ''
			ibn = "NOREAD"
			zone = "NOREAD"
		elif IBNCount == 1:	
			sortSize = IBNresults[0]['sort_size']
			ibn = IBNresults[0]['_id']
			zone = IBNresults[0]['zone']	

		
		Autostore_results = system.db.runPrepQuery("""
			select *
			from AutoStore_RouteTable
			where Route_Code = ? and BoxSize = ?
			""", [zone,sortSize],'SQLServer')
			
		results = Autostore_results
		route_code = zone
		
		
		
	if 	Autostore_results:
		row = Autostore_results[0]
		try:
			Dim_results = system.db.runPrepQuery("""
				select IBN,Length,Width,Height
				from Dimensioner_InductSorter_1
				where IBN = ?
				""", [ibn],'SQLServer')
				
			dim_row = Dim_results[0]
			length = (float(dim_row['Length'])/10)
			width = (float(dim_row['width'])/10)
			height = (float(dim_row['height'])/10)
		except:
			length = 12.5
			width = 12.5
			height = 12.5
		
		if height >= 12.5:
			bitArray = (1<<(7-1))
		else:
			bitArray = row['Binary_Destination']
		
		
					
		
		system.tag.writeAsync('[default]NE_Receiving/Autostore/autostoreroute', row['String_Destination'])
		
		
	else:
			
		results = system.db.runPrepQuery("""
		select r.*
		from route_table1 as r
		where r.route_code = ?
		""", [zone],'SQLServer')
			
		
			
		
		# if a route wasn't found, then fail back to direct route data
		if not results:
			zone = 'NOIBN'		
			# query the route directly
			results = system.db.runPrepQuery("""
			select r.*
			from route_table1 as r
			where r.route_code = ?
			""", [zone],'SQLServer')
		
		if not results:
			raise RuntimeError("No routes or fallbacks found for %s" % barcode)
		
		if not Autostore_results:
			# grab the top entry
			row = results[0]
				
				# Start with no routes	
			bitArray = 0
			route_code = ''
			for selected,columnName in zip(row, results.columnNames):
					
				if columnName == 'Route_Code':
					route_code = selected
					continue
			
				if not columnName.startswith('Lane_'):
					continue
				
				# Get the second half on the underscore.
				# (rpartition splits on a thing, always retruning
				#  the left, split thing, and right of it)
				# And make it an int so we can shift on it
				# ... minus one because we are zero indexed, and lanes are one-indexed
				shift = int(columnName.rpartition('_')[2]) - 1
			
				# Take the result bit array so far, 
				#  and or it with the value SQL returned, 
				#  bit shifted the number of lanes 
				bitArray |= selected << shift
			
			
		

	data = {
		'IGN_Barcode_Returned': barcode,
		'IGN_Destination_Returned': bitArray,	
		'IGN_IndexID_Returned': sequence_id,	
		'IGN_GotData_Returned': True,
		
		'Get_Time': timestart,
		'RouteCode_Returned': route_code,
		}
	

	# delay for testing purposes
#	if random() < 0.8: # percent slowed
#		sleep(2*random()) # time in seconds (random is 0.0-1.0)
			
	push_sequence(source_path, sequence_id, data)
	mongoupdate(data)
	log_event(1, data)

@async(name="Handshake2-DumpData")
def dump_data(source_path, data):
	parent_dest = '/'.join(source_path.split('/')[:-2] + ['Got_Data'])
	
	mode = data.pop('mode', 2)
	
	i = 0
	while system.tag.read(parent_dest + '/' + 'IGN_GotData_Returned').value:
		sleep(CLEAR_WAIT_TIME)
		i += CLEAR_WAIT_TIME
		if i > FAILSAFE_TIMEOUT:
			system.util.getLogger('Handshake2').warn("Writeback payload: Took too long to see IGN_GotData_Returned clear for %s" % (source_path,))
			return
#			raise RuntimeError("Took too long to receive IGN_GotData_Returned clear for %s (with %r)" % (source_path, data))
	
	# if we DID have to wait, then wait just a moment longer to make sure the PLC
	# has time to catch up
	if i > 0:
		sleep(CLEAR_WAIT_TIME)
	
	tag_paths = []
	values = []
	for key,value in data.items():
		tag_paths.append(parent_dest + '/' + key)
		values.append(value)

	opc_fqv_paths = [tag_path + '.OpcItemPath' for tag_path in tag_paths]
	
	def write_block(qualified_values, tag_paths=tag_paths, values=values, ack_tag='IGN_GotData_Returned', data=data, mode=mode):
		opc_paths = []
		opc_values = []
		for qv, tag_path, value in zip(qualified_values, tag_paths, values):
			if tag_path.endswith('/' + ack_tag):
				ack_path = qv.value
				ack_value = value
			else:
				opc_paths.append(qv.value)
				opc_values.append(value)
		
		results = system.opc.writeValues('Ignition OPC-UA Server', opc_paths, opc_values)
		
		system.util.getLogger('FAILACK').trace('ACK: %s on %s with %r' % (parent_dest, ack_path, ack_value))
		ack_result = system.opc.writeValue('Ignition OPC-UA Server', ack_path, ack_value)
		
		data['Got_Time'] = datetime.now().isoformat()
		log_event(mode, data)

	system.tag.readAsync(opc_fqv_paths, write_block)
	

def push_sequence(source_path, sequence_id, data):
	#Uncomment this to prevent overwrites and throw an error on repeated sequence IDs
	#assert (sequence_id, source_path) not in ExtraGlobal, "Cache is backed up! Sequence ID already in cache: [%s:%s]" % (sequence_id, source_path)
	assert isinstance(data, dict), "Data object should be a dictionary here."

	parent_dest = '/'.join(source_path.split('/')[:-2] + ['Get_Data'])
	
	# check if the sequence already exists and is (somehow) straggling
	if ExtraGlobal.get(sequence_id, source_path):
		system.util.getLogger('Handshake2').warn('Push sequence: Sequence [%d] already cached for %s: clearing to make room for next!' % (sequence_id, source_path) )
		try:
			del ExtraGlobal[sequence_id, source_path]
		except KeyError:
			pass # failsafe
	
	ExtraGlobal.stash(data, 
					  label=sequence_id, scope=source_path, 
					  lifespan=CACHE_LIFESPAN, 
					  callback=partial(flush_next_sequence, source_path, data)) 
					  
	system.util.getLogger('Handshake2').trace('>PUSH< [%d] %r' % (sequence_id, data))
#		'>PUSH< (#%d) for [%03d] %r >>> %r' % (len(ExtraGlobal.keys(scope=source_path)), sequence_id,
#						          list(ExtraGlobal.keys(scope=source_path)), data) )
					  
	flush_next_sequence(source_path)
	

def flush_next_sequence(source_path, data=None):
	# semaphore to prevent multithreaded interaction
	# but also return data to make sure the cache stays viable
	# (scoped to the 'handshake flushing' so that it can be checked independently)
	if ExtraGlobal.setdefault(source_path, 'handshake2 flushing', False):
		return data
		
	# If no more sequences to flush, then signal to stop
	if not ExtraGlobal.keys(source_path):
		ExtraGlobal[source_path, 'handshake2 flushing'] = False
		return

	# turn on semaphore to the current sequence getting worked on
	sequence_id = ExtraGlobal.keys(source_path)[0]

	ExtraGlobal[source_path, 'handshake2 flushing'] = sequence_id
	
	try:
#		data = ExtraGlobal.pop(sequence_id, source_path)
		data = ExtraGlobal[sequence_id, source_path]
		del ExtraGlobal[sequence_id, source_path]
			
		# write results back
		dump_data(source_path, data)
	
		system.util.getLogger('Handshake2').trace('<POPD> [%d] %r' % (sequence_id, data))
	#		'<POPD> (#%d) for [%03d] %r >>> %r' % (len(ExtraGlobal.keys(scope=source_path)), sequence_id,
	#						          list(ExtraGlobal.keys(scope=source_path)), data) )
	except Exception, error:
		system.util.getLogger('Handshake2').warn('Flush: Error in completing handshake [%d] for %s: %r' % (sequence_id, source_path, error))
	
	# clear the semaphore and try again; when exhausted it'll just end
	ExtraGlobal[source_path, 'handshake2 flushing'] = False
	
	# continue flushing if needed
	if ExtraGlobal.keys(source_path):
		flush_next_sequence(source_path, data)
		# don't return anything, since this is just continuing the flush process
		#return None

def mongoupdate(data):
	payload = {
			'IGN_Barcode_Returned': data['IGN_Barcode_Returned'],
			'IGN_Destination_Returned': data['IGN_Destination_Returned'],	
			'IGN_IndexID_Returned': data['IGN_IndexID_Returned'],
			'TimeStamp': datetime.utcnow(),
			'RouteCode_Returned': data['RouteCode_Returned']
			}
	db.NE_Receiving_Induct.insert(payload)