"""
	Snapshot versioning of Ignition resources
	
	Take stuff in Ignition and put it to disk using words. 
	Then let other programs read those words and tell you what's different!
	
	This is a one-way utility: it dumps TO disk, FROM Ignition.
	  It could go the other way too in _some_ circumstances, but that's not the goal.
	The goal here is to make it possible to comprehensively and confidently know
	  what is different between two projects (or one project's differences over time).
	  And with enough cleverness, you can inspect history and compare many projects!
"""

import sys
import os, shutil, re

from shared.tools.snapshot.utils import getDesignerContext


# Load in extractors
RESOURCE_EXTRACTORS = {
	'__folder': None,
	}

BULK_GLOBAL_EXTRACTORS = []
BULK_PROJECT_EXTRACTORS = []

_EXTRACTORS = [
	'shared.tools.snapshot.ia.global',
	'shared.tools.snapshot.ia.project',
	#'shared.tools.snapshot.ia.reporting',
	'shared.tools.snapshot.ia.tags',
	'shared.tools.snapshot.ia.vision',
	'shared.tools.snapshot.ia.webdev',
	#'shared.tools.snapshot.sepasoft.webservices',
	#'shared.tools.snapshot.sepasoft.model',
	]



from com.inductiveautomation.ignition.common.xmlserialization import SerializationException

for module_path in _EXTRACTORS:
	try:
		assert module_path.startswith(_HOTLOADING_SCOPE), "Extractors are expected to be hot loaded from the `%s` scripts." % _HOTLOADING_SCOPE
		module = reduce(getattr, module_path.split('.')[1:], shared)

		RESOURCE_EXTRACTORS.update(getattr(module, 'EXTRACTORS', {}))
		BULK_GLOBAL_EXTRACTORS += getattr(module, 'BULK_GLOBAL_EXTRACTORS', [])
		BULK_PROJECT_EXTRACTORS += getattr(module, 'BULK_PROJECT_EXTRACTORS', [])
	except:
		pass

	
def nop_dict(*args, **kwargs):
	return {}


def deserializeAndExtract(resource, extractor):
	context = getDesignerContext()
	deserializer = context.createDeserializer()
	#data_context = deserializer.deserializeBinary(resource.getData())
	resource_objects = {}
	for key in resource.getDataKeys():
		raw_data = resource.getData(key)
		try:
			data_context = deserializer.deserializeBinary(raw_data)
			for root_object in data_context.getRootObjects():
				resource_objects[str(key)] = root_object
		#resource_objects.extend(data_context.getRootObjects())
		except SerializationException:
#				print 'Failsafe: ', resource.getResourceId(), resource.getFolderPath()
			try:
				resource_objects[str(key)] = ''.join(chr(c) for c in raw_data)
			except:
				resource_objects[str(key)] = raw_data

	return extractor(resource_objects)
		

def extract_resources(resources, category='', context=None):
	"""Extract resource data. Category prepends to each resource's path"""
	if context is None:
		context = getDesignerContext()
			
	deserializer = context.createDeserializer()
	
	extracted_data = {}
	
	for res_path, resource in resources.items():
		res_type = resource.getResourceType()
		extractor = RESOURCE_EXTRACTORS.get(res_type, None)
		
		if not extractor:
			#print 'No extractor for %s' % res_type
			continue
		
		try:
			data_context = deserializer.deserializeBinary(resource.getData())
		except SerializationException, error:
			print 'Resource did not deserialize: %s\n%r (type: %s)' % (res_path, resource, res_type)
			print '    Err: %r' % error
			
		resource_objects = [obj for obj in data_context.getRootObjects()]
		
		dest_path, _, _ = res_path.rpartition('/')
		
		try:
			res_name = resource.getName()
			if res_name:
				dest_path += '/' + res_name
		except:
			pass

		if category:
			dest_path = category + '/' + dest_path
		
		# Gather any extra bits of context if the extractor needs it
		# (Skip the first, since it will always be resource_objects)
		keyword_arguments = {}
		num_extra_args = extractor.func_code.co_argcount-1
		if num_extra_args:
			for kwarg in extractor.func_code.co_varnames[1:][:num_extra_args]:
				keyword_arguments[kwarg] = locals()[kwarg]
		extracted_data[dest_path] = extractor(resource_objects, **keyword_arguments)
			
	return extracted_data


def dump_extracted_resources(destination_folder, extracted_data, purge_first=False, suffix_filter='.*'):
	"""
	Dump the contents of the given extracted data into the destination folder.
	If purge_first is set True, then the destination will be deleted before dumping.
	"""
	if purge_first and os.path.exists(destination_folder):
		for subdir in os.listdir(destination_folder):
			if subdir.startswith('.'):
				continue
			try:
				shutil.rmtree(destination_folder + '/' + subdir)
			except OSError:
				print 'Destination folder not completely purged - check for open files!'
	
	suffix_pattern = re.compile(suffix_filter, re.I)
	
	for resource_path, resource_details in extracted_data.items():
		resource_path, _, name = resource_path.rpartition('/')
		
		destination = '%s/%s' % (destination_folder, resource_path)
				
		for suffix, data in resource_details.items():
			
			if not suffix_pattern.match(suffix):
				continue
				
			filepath = destination

			if suffix.startswith('.'):
				if not name:
					# remove the slash, since this is standalone
					filepath = '%s%s' % (filepath[:-1], suffix)
				else:
					filepath = '%s/%s%s' % (filepath, name, suffix)
			else:
				filepath = '%s/%s' % (filepath, suffix)

			if data is None:
				print 'No data! %s' % filepath
				continue


			if not os.path.exists(filepath.rpartition('/')[0]):
				os.makedirs(filepath.rpartition('/')[0])
			
			f = open(filepath, 'wb')
			f.write(data)
			f.close()
#			with open(filepath, 'wb') as f:
#				f.write(data)

from com.inductiveautomation.ignition.common.project import ProjectFileUtil
from java.io import FileOutputStream

def dump_raw_resource(filepath, resources):
	"""
	Dump the raw resource file's binary stuff as a packed project zip to disk.
	"""
	if filepath.endswith('/'):
		filepath = filepath[:-1]
	if not filepath.endswith('.zip'):
		filepath += '.zip'
		
	if not os.path.exists(filepath.rpartition('/')[0]):
		os.makedirs(filepath.rpartition('/')[0])
			
	manifest = getDesignerContext().getProject().getManifest()
	
	fos = FileOutputStream(filepath)
	
	# allow either a list or just one
	if not isinstance(resources, list):
		resources =  [resources]
	
	ProjectFileUtil.exportToZip(manifest, resources, fos)
	fos.close()

				

def coredump(destination_folder):
	#destination_folder = 'C:/Workspace/temp/extraction-2'

	context = getDesignerContext()
		
	global_project = context.getGlobalProject().getProject()
	designer_project = context.getProject()

	global_resources = dict(
		('%s/%s' % (resource.getResourceType(), global_project.getFolderPath(resource.getResourceId())) or '', resource)
		for resource
		in global_project.getResources()
		)
	
	project_resources = dict(
		('%s/%s' % (resource.getResourceType(), designer_project.getFolderPath(resource.getResourceId())) or '', resource)
		for resource
		in designer_project.getResources()
		)
	
	extracted_resources = {}
	
	extracted_resources['project/properties'] = RESOURCE_EXTRACTORS['project/properties'](context)
	
	extracted_resources.update(extract_resources(global_resources, 'global'))
	extracted_resources.update(extract_resources(project_resources, 'project'))
	
	for bulk_extractor in BULK_GLOBAL_EXTRACTORS:
		extracted_resources.update(bulk_extractor(global_project))

	for bulk_extractor in BULK_PROJECT_EXTRACTORS:
		extracted_resources.update(bulk_extractor(designer_project))
		
	dump_extracted_resources(destination_folder, extracted_resources, purge_first=True)
