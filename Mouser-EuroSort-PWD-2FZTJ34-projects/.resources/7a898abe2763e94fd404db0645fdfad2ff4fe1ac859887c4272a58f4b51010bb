"""
	Resilient get/got handshake framework
	
	
	
	Here's the test table to use:
	
use pwd
go

/*
truncate table Handshake_Log
*/

select top 1000 
		barcode, routecode, destination, seq
	,	DATEDIFF(millisecond, get_time, got_time) as span
from Handshake_Log
where mode = 2
order by dt desc, mode desc



/*

drop table Handshake_Log
go

create table Handshake_Log (
	id int identity(1,1) not null,
	dt datetime2 not null,
	mode int not null,
	barcode varchar(50) not null,
	routecode varchar(50) null,
	destination int null,
	seq int not null,

	get_time datetime2 null,
	got_time datetime2 null,

	CONSTRAINT pk_Handshake_Log__id PRIMARY KEY CLUSTERED ([ID] ASC)
)

ALTER TABLE Handshake_Log
	ADD CONSTRAINT df_Handshake_Log__dt
	DEFAULT GETDATE()
	FOR dt
*/
"""


from shared.tools.global import ExtraGlobal
from shared.tools.thread import async
from shared.tools.meta import is_redundant_active
from functools import partial

from time import sleep
from random import random
from datetime import datetime


def log_event(mode, data):
	results = system.db.runPrepUpdate("""
		insert into Handshake_Log (
			mode
		,	barcode
		,	routecode
		,	destination
		,	seq
		,	get_time
		,	got_time
		,	sql_time
		) values (?,?,?,?,?,?,?,?)	
		""",[
			mode
		,	data['IGN_Barcode_Returned']
		,	data.get('IGN_RouteCode_Returned', data.get('RouteCode_Returned'))
		,	data['IGN_Destination_Returned']
		,	data['IGN_IndexID_Returned']		
		,	data.get('Get_Time')		
		,	data.get('Got_Time')
		,	data.get('Sql_Time')
		], 'SQLServer')
	


CACHE_LIFESPAN = 3.0 # seconds

CLEAR_WAIT_TIME  = 0.026
FAILSAFE_TIMEOUT = 6.0

ERROR_BARCODES = set(['', 'NOREAD'])


@async(name="Handshake-GatherData")
def gather_data(source_path):
	"""
		Get the data that needs to be processed.
		
		This uses direct OPC reads on the spot, 
		  and writes the ACK as soon as it can.
	"""
	timestart = datetime.now().isoformat()
	
	parent_dest = '/'.join(source_path.split('/')[:-2] + ['Get_Data'])

	# read the needed values in
	sequence_id, barcode = [
		qv.value for qv in 
		system.tag.readBlocking([
			parent_dest + '/' + 'IGN_IndexID_Sent',
			parent_dest + '/' + 'IGN_Barcode_Sent'
			])]

	system.tag.writeAsync([parent_dest + '/' + 'IGN_GetData_ACK'], [True])

	barcodes = barcode.split(',')
	
	tote_query = []
	tote = 'RVT'
	for i in range(len(barcodes)):
		
		check = barcodes[i]
		
		if check.startswith("RVT"):
			tote_query.append(check)
		elif check.startswith("TSBX"):
			tote_query.append(check)	
			
	if not tote_query:
	
		
		# query DB for route
		results = system.db.runPrepQuery("""
			select r.*
			from Production as p
				inner join route_table1 as r
					on (p.Zone = r.route_code and p.Zone <> '')
					or (r.route_code = 'NODESTINATION' and p.Zone = '')
			where p.IBN in (%s)
			"""  % ', '.join('?' for b in barcodes),
			barcodes,'SQLServer')
	elif tote_query:
		results = system.db.runPrepQuery("""
			select r.*
			from route_table1 as r
			where r.route_code = ?
			""", [tote],'SQLServer')		
	
	
	error_code = 'NOIBN'
	
	if len(results) > 1:
		error_code = 'MULTIPLEIBN'
		results = None # clear the results
		
	# if a route wasn't found, then fail back to direct route data
	if not results:		
		# query the route directly
		results = system.db.runPrepQuery("""
			select r.*
			from route_table1 as r
			where r.route_code = ?
			""", [error_code],'SQLServer')	
	
		if not results:
			raise RuntimeError("No routes or fallbacks found for %s" % barcode)
	
	# grab the top entry
	row = results[0]
	
	# Start with no routes	
	bitArray = 0
	route_code = ''
	
	for selected,columnName in zip(row, results.columnNames):
	
		if columnName == 'Route_Code':
			route_code = selected
			continue
	
		if not columnName.startswith('Lane_'):
			continue
		
		# Get the second half on the underscore.
		# (rpartition splits on a thing, always retruning
		#  the left, split thing, and right of it)
		# And make it an int so we can shift on it
		# ... minus one because we are zero indexed, and lanes are one-indexed
		shift = int(columnName.rpartition('_')[2]) - 1
	
		# Take the result bit array so far, 
		#  and or it with the value SQL returned, 
		#  bit shifted the number of lanes 
		bitArray |= selected << shift

	data = {
		'IGN_Barcode_Returned': barcode,
		'IGN_Destination_Returned': bitArray,	
		'IGN_IndexID_Returned': sequence_id,	
		'IGN_GotData_Returned': True,
		
		'Get_Time': timestart,
		'RouteCode_Returned': route_code,
		}
	

	# delay for testing purposes
#	if random() < 0.8: # percent slowed
#		sleep(2*random()) # time in seconds (random is 0.0-1.0)
			
	push_sequence(source_path, sequence_id, data)

	log_event(1, data)

@async(name="Handshake-DumpData")
def dump_data(source_path, data):
	parent_dest = '/'.join(source_path.split('/')[:-2] + ['Got_Data'])
	
	mode = data.pop('mode', 2)
	
	i = 0
	while system.tag.read(parent_dest + '/' + 'IGN_GotData_Returned').value:
		sleep(CLEAR_WAIT_TIME)
		i += CLEAR_WAIT_TIME
		if i > FAILSAFE_TIMEOUT:
			system.util.getLogger('Handshake').warn("Writeback payload: Took too long to see IGN_GotData_Returned clear for %s" % (source_path,))
			return
#			raise RuntimeError("Took too long to receive IGN_GotData_Returned clear for %s (with %r)" % (source_path, data))
	
	# if we DID have to wait, then wait just a moment longer to make sure the PLC
	# has time to catch up
	if i > 0:
		sleep(CLEAR_WAIT_TIME)
	
	tag_paths = []
	values = []
	for key,value in data.items():
		tag_paths.append(parent_dest + '/' + key)
		values.append(value)

	opc_fqv_paths = [tag_path + '.OpcItemPath' for tag_path in tag_paths]
	
	def write_block(qualified_values, tag_paths=tag_paths, values=values, ack_tag='IGN_GotData_Returned', data=data, mode=mode):
		opc_paths = []
		opc_values = []
		for qv, tag_path, value in zip(qualified_values, tag_paths, values):
			if tag_path.endswith('/' + ack_tag):
				ack_path = qv.value
				ack_value = value
			else:
				opc_paths.append(qv.value)
				opc_values.append(value)
		
		results = system.opc.writeValues('Ignition OPC-UA Server', opc_paths, opc_values)
		
		system.util.getLogger('FAILACK').trace('ACK: %s on %s with %r' % (parent_dest, ack_path, ack_value))
		ack_result = system.opc.writeValue('Ignition OPC-UA Server', ack_path, ack_value)
		
		data['Got_Time'] = datetime.now().isoformat()
		log_event(mode, data)

	system.tag.readAsync(opc_fqv_paths, write_block)
	

def push_sequence(source_path, sequence_id, data):
	#Uncomment this to prevent overwrites and throw an error on repeated sequence IDs
	#assert (sequence_id, source_path) not in ExtraGlobal, "Cache is backed up! Sequence ID already in cache: [%s:%s]" % (sequence_id, source_path)
	assert isinstance(data, dict), "Data object should be a dictionary here."

	parent_dest = '/'.join(source_path.split('/')[:-2] + ['Get_Data'])
	
	# check if the sequence already exists and is (somehow) straggling
	if ExtraGlobal.get(sequence_id, source_path):
		system.util.getLogger('Handshake').warn('Push sequence: Sequence [%d] already cached for %s: clearing to make room for next!' % (sequence_id, source_path) )
		try:
			del ExtraGlobal[sequence_id, source_path]
		except KeyError:
			pass # failsafe
	
	ExtraGlobal.stash(data, 
					  label=sequence_id, scope=source_path, 
					  lifespan=CACHE_LIFESPAN, 
					  callback=partial(flush_next_sequence, source_path, data)) 
					  
	system.util.getLogger('Handshake').trace('>PUSH< [%d] %r' % (sequence_id, data))
#		'>PUSH< (#%d) for [%03d] %r >>> %r' % (len(ExtraGlobal.keys(scope=source_path)), sequence_id,
#						          list(ExtraGlobal.keys(scope=source_path)), data) )
					  
	flush_next_sequence(source_path)
	

def flush_next_sequence(source_path, data=None):
	# semaphore to prevent multithreaded interaction
	# but also return data to make sure the cache stays viable
	# (scoped to the 'handshake flushing' so that it can be checked independently)
	if ExtraGlobal.setdefault(source_path, 'handshake flushing', False):
		return data
		
	# If no more sequences to flush, then signal to stop
	if not ExtraGlobal.keys(source_path):
		ExtraGlobal[source_path, 'handshake flushing'] = False
		return

	# turn on semaphore to the current sequence getting worked on
	sequence_id = ExtraGlobal.keys(source_path)[0]

	ExtraGlobal[source_path, 'handshake flushing'] = sequence_id
	
	try:
#		data = ExtraGlobal.pop(sequence_id, source_path)
		data = ExtraGlobal[sequence_id, source_path]
		del ExtraGlobal[sequence_id, source_path]
			
		# write results back
		dump_data(source_path, data)
	
		system.util.getLogger('Handshake').trace('<POPD> [%d] %r' % (sequence_id, data))
	#		'<POPD> (#%d) for [%03d] %r >>> %r' % (len(ExtraGlobal.keys(scope=source_path)), sequence_id,
	#						          list(ExtraGlobal.keys(scope=source_path)), data) )
	except Exception, error:
		system.util.getLogger('Handshake').warn('Flush: Error in completing handshake [%d] for %s: %r' % (sequence_id, source_path, error))
	
	# clear the semaphore and try again; when exhausted it'll just end
	ExtraGlobal[source_path, 'handshake flushing'] = False
	
	# continue flushing if needed
	if ExtraGlobal.keys(source_path):
		flush_next_sequence(source_path, data)
		# don't return anything, since this is just continuing the flush process
		#return None

	
	
	
